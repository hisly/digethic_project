{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cdb9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeedc9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(\"OnlineNewsPopularity.csv\")\n",
    "col_names = original_data.columns.tolist()\n",
    "for index,value in enumerate(col_names):\n",
    "    col_names[index]= value.replace(\" \",\"\")\n",
    "    \n",
    "original_data.columns=col_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6134cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['url',\n",
    "             'timedelta',\n",
    "             'n_non_stop_words',\n",
    "             'n_non_stop_unique_tokens',\n",
    "             'weekday_is_monday',\n",
    "             'weekday_is_tuesday',\n",
    "             'weekday_is_wednesday', \n",
    "             'weekday_is_thursday', \n",
    "             'weekday_is_friday',\n",
    "             'weekday_is_saturday', \n",
    "             'weekday_is_sunday',\n",
    "             'kw_max_max',\n",
    "             'kw_max_min',\n",
    "             'kw_max_avg',\n",
    "             'self_reference_min_shares',\n",
    "             'self_reference_max_shares']\n",
    "extracted_data = original_data.drop(labels=drop_list, axis = 1)\n",
    "\n",
    "# 1st quartile (25%)\n",
    "Q1 = np.percentile(extracted_data[\"shares\"], 25)\n",
    "# 3rd quartile (75%)\n",
    "Q3 = np.percentile(extracted_data[\"shares\"], 75)\n",
    "# Interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# outlier step\n",
    "outlier_step = 3 * IQR\n",
    "upper_boundary = Q3 + outlier_step\n",
    "extracted_data = extracted_data[extracted_data[\"shares\"] <= upper_boundary]\n",
    "extracted_data.reset_index(drop=True)\n",
    "extracted_data.loc[extracted_data[\"n_unique_tokens\"]==701,\"n_unique_tokens\"] = 0.701\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141bb22a",
   "metadata": {},
   "source": [
    "# 4.1  LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff92ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "training_set = extracted_data.drop(labels=[\"shares\"],axis=1)\n",
    "target_set = extracted_data[\"shares\"]\n",
    "\n",
    "scaler_list = training_set.columns.tolist()\n",
    "\n",
    "training_set = scaler.fit_transform(training_set)\n",
    "training_set = pd.DataFrame(training_set,columns=scaler_list)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(training_set,target_set,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b92db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the root mean squared error is: 348164326599.41876\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "rmse = mean_squared_error(y_pred, y_test,squared=False)\n",
    "print( f\"the root mean squared error is: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263c8717",
   "metadata": {},
   "source": [
    "removing the outliers from Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81ca385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_new = extracted_data.drop(labels=[\"shares\"],axis=1)\n",
    "\n",
    "\n",
    "training_set_new = training_set_new.mask((training_set_new - training_set_new.mean()).abs() > 2 * training_set_new.std())\n",
    "training_set_new = training_set_new.fillna(training_set_new.mean())\n",
    "training_set_new = scaler.fit_transform(training_set_new)\n",
    "training_set_new = pd.DataFrame(training_set_new,columns=scaler_list)\n",
    "\n",
    "X_train_new,X_test_new,y_train_new,y_test_new = train_test_split(training_set_new,target_set,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780f9a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the root mean squared error after removing the outliers is: 1502.0854100358795\n"
     ]
    }
   ],
   "source": [
    "lin_reg.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_linear = lin_reg.predict(X_test_new)\n",
    "new_rmse = mean_squared_error(y_pred_linear, y_test_new,squared=False)\n",
    "print( f\"the root mean squared error after removing the outliers is: {new_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5764cf2",
   "metadata": {},
   "source": [
    "Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29753525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the root mean squared error with polynomial is: 1507.1793228532115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_poly = poly_features.fit_transform(X_train_new)\n",
    "X_test_poly = poly_features.fit_transform(X_test_new)\n",
    "\n",
    "lin_reg.fit(X_train_poly, y_train_new)\n",
    "y_pred_poly = lin_reg.predict(X_test_poly)\n",
    "rmse = mean_squared_error(y_pred_poly, y_test_new,squared=False)\n",
    "print( f\"the root mean squared error with polynomial is: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d22ef8",
   "metadata": {},
   "source": [
    "Regularized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeda6dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the root mean squared error with ridge regressor is: 1502.1080608475513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge(alpha=1, solver=\"cholesky\", random_state=42)\n",
    "ridge_reg.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_ridge = ridge_reg.predict(X_test_new)\n",
    "rmse = mean_squared_error(y_pred_ridge, y_test_new,squared=False)\n",
    "print( f\"the root mean squared error with ridge regressor is: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbcecb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the root mean squared error with lasso regressor is: 1502.1833956259707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha=0.1, random_state=42)\n",
    "lasso_reg.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_lasso = lasso_reg.predict(X_test_new)\n",
    "rmse = mean_squared_error(y_pred_lasso, y_test_new,squared=False)\n",
    "print( f\"the root mean squared error with lasso regressor is: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31506b2d",
   "metadata": {},
   "source": [
    "# 4.2 Influence of Dataset size on Training & Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8afaa875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_size_curve(model, X, y):\n",
    "    X_train, X_test, y_train, y_vest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    train_errors, test_errors = [], []\n",
    "    m = 100\n",
    "    while m < (len(X_train) + 1):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "        test_errors.append(mean_squared_error(y_test, y_test_predict))\n",
    "        m += 1000\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train error\")\n",
    "    plt.plot(np.sqrt(test_errors), \"b-\", linewidth=3, label=\"test error\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14)   \n",
    "    plt.xlabel(\"Training set size\", fontsize=14)\n",
    "    plt.ylabel(\"RMSE\", fontsize=14)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "873dc3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_size_curve(lin_reg, training_set_new, target_set)\n",
    "plt.axis([0, 31, 1250, 1600])           \n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd52dd1",
   "metadata": {},
   "source": [
    "# 4.3  Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c45b2a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=8, min_samples_leaf=40, n_estimators=120,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'n_estimators': list(range(100,121,10)), 'min_samples_leaf': list(range(40,47,3)), 'max_depth': [6,8]}\n",
    "grid_search_cv = GridSearchCV(RandomForestRegressor(random_state=42), params, verbose=1, cv=3)\n",
    "grid_search_cv.fit(X_train_new[:10000], y_train_new[:10000])\n",
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c6fec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the root mean squared error with Regressor hyperparameter turning is 1489.9410884423066\n"
     ]
    }
   ],
   "source": [
    "y_pred_rnd = grid_search_cv.predict(X_test_new)\n",
    "rmse = mean_squared_error(y_pred_rnd, y_test_new,squared=False)\n",
    "print(f\"the root mean squared error with Regressor hyperparameter turning is {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65bcea2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the root mean squared error with no hyperparameter turning is 1513.5017377439776\n",
      "the root mean squared error with Classifier hyperparameter turning is 1490.4769664930764\n"
     ]
    }
   ],
   "source": [
    "rnd_ori_para = RandomForestRegressor(random_state=42)\n",
    "rnd_clf_para = RandomForestRegressor(max_depth=8, min_samples_leaf=50, n_estimators=90, random_state=42)\n",
    "\n",
    "rnd_ori_para.fit(X_train_new[:10000], y_train_new[:10000])\n",
    "rnd_clf_para.fit(X_train_new[:10000], y_train_new[:10000])\n",
    "\n",
    "y_pred_ori = rnd_ori_para.predict(X_test_new)\n",
    "y_pred_clf = rnd_clf_para.predict(X_test_new)\n",
    "\n",
    "regressor_list = [\"with no hyperparameter turning\", \"with Classifier hyperparameter turning\"]\n",
    "y_pred_list = [y_pred_ori, y_pred_clf]\n",
    "\n",
    "for regressor, y_pred in zip(regressor_list,y_pred_list):\n",
    "    rmse = mean_squared_error(y_pred, y_test,squared=False)\n",
    "    \n",
    "    print(f\"the root mean squared error {regressor} is {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8f316",
   "metadata": {},
   "source": [
    "# 4.4  Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d38303ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acdfbd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 regressors are used for the first layer\n",
    "\n",
    "models=[RandomForestRegressor(max_depth=8, min_samples_leaf=46, n_estimators=110,random_state=42),\n",
    "        AdaBoostRegressor(learning_rate=0.5, n_estimators=80, random_state=42),\n",
    "        SVR(),\n",
    "        GradientBoostingRegressor(n_estimators=110,random_state=42),\n",
    "        Ridge(alpha=1, solver=\"cholesky\", random_state=42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6089dbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29503\n",
      "7376\n"
     ]
    }
   ],
   "source": [
    "# the dataset is transformed to ndArray matrix, since in Dataframe and Series the index will be shuffled in KFold and cause unmachting problem\n",
    "\n",
    "x_train = X_train_new.values\n",
    "y_train = y_train_new.values\n",
    "x_test = X_test_new.values\n",
    "y_test = y_test_new.values\n",
    "\n",
    "kf=KFold(n_splits=5)\n",
    "n_train=x_train.shape[0]\n",
    "n_test=x_test.shape[0]           \n",
    "print(n_train)\n",
    "print(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c39155f",
   "metadata": {},
   "source": [
    "Define a function to return the predicted value as feature.The first return value is the feature of the training set for the second layer model; the second return value is the prediction of the test set by the first layer model, which will be used as the X_test of the training set for the second layer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8644c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(model,x_train,y_train,x_test):\n",
    "    oof_train=np.zeros((n_train,))     # create a 29503 * 1 zero matrix  \n",
    "    oof_test=np.zeros((n_test,))       #create a 7376 * 1 zero matrix  \n",
    "    oof_test_skf=np.zeros((5,n_test))  # 5 * 7376 zero matrix\n",
    "    for i,(train_index,test_index) in enumerate(kf.split(x_train)):\n",
    "        kf_x_train=x_train[train_index]            # 23602 instances from training set in every fold\n",
    "        kf_y_train=y_train[train_index]            # 23602 target values from training set in every fold\n",
    "        kf_x_test=x_train[test_index]              #  5901 instances from test set in every fold\n",
    "        model=model.fit(kf_x_train,kf_y_train)\n",
    "        oof_train[test_index]=model.predict(kf_x_test)        #every fold can give us 5901 prediction values from Kfold，then we can get 29503 predictions for training set\n",
    "        oof_test_skf[i,:]=model.predict(x_test)               #every fold can also give 7376 prediction values from test set.\n",
    "    oof_test[:]=oof_test_skf.mean(axis=0)            #calculate the mean value of 5 times prediction from the test se \n",
    "    return oof_train,oof_test              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31117434",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_models=len(models)\n",
    "xtrain_new=np.zeros((n_train,number_models))\n",
    "xtest_new=np.zeros((n_test,number_models))\n",
    "\n",
    "# the output as meta feature will be trained in second layer \n",
    "for i,regressor in enumerate(models):\n",
    "    xtrain_new[:,i],xtest_new[:,i]=get_oof(regressor,x_train,y_train,x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e07daa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2075.045395</td>\n",
       "      <td>2964.841065</td>\n",
       "      <td>1398.344827</td>\n",
       "      <td>2039.361555</td>\n",
       "      <td>1956.637421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2392.099039</td>\n",
       "      <td>2893.142397</td>\n",
       "      <td>1353.234486</td>\n",
       "      <td>2367.791394</td>\n",
       "      <td>1934.902312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2375.726598</td>\n",
       "      <td>3017.861569</td>\n",
       "      <td>1496.913724</td>\n",
       "      <td>2620.756481</td>\n",
       "      <td>2357.003408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467.677248</td>\n",
       "      <td>2220.532612</td>\n",
       "      <td>1181.521401</td>\n",
       "      <td>1491.529684</td>\n",
       "      <td>1903.669717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949.033519</td>\n",
       "      <td>2400.175031</td>\n",
       "      <td>1204.608386</td>\n",
       "      <td>1713.527779</td>\n",
       "      <td>1824.986944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29498</th>\n",
       "      <td>1289.230163</td>\n",
       "      <td>1991.285965</td>\n",
       "      <td>1178.917172</td>\n",
       "      <td>1283.131391</td>\n",
       "      <td>1222.833398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29499</th>\n",
       "      <td>2007.638607</td>\n",
       "      <td>2876.992553</td>\n",
       "      <td>1325.959616</td>\n",
       "      <td>2008.751715</td>\n",
       "      <td>2183.280494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29500</th>\n",
       "      <td>1364.185118</td>\n",
       "      <td>2148.467800</td>\n",
       "      <td>1147.881760</td>\n",
       "      <td>1383.008785</td>\n",
       "      <td>1147.514338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29501</th>\n",
       "      <td>1713.124251</td>\n",
       "      <td>2284.655204</td>\n",
       "      <td>1263.797978</td>\n",
       "      <td>1751.759765</td>\n",
       "      <td>1155.093199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29502</th>\n",
       "      <td>1720.344804</td>\n",
       "      <td>2382.447442</td>\n",
       "      <td>1417.939307</td>\n",
       "      <td>1830.297473</td>\n",
       "      <td>1845.863522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29503 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4\n",
       "0      2075.045395  2964.841065  1398.344827  2039.361555  1956.637421\n",
       "1      2392.099039  2893.142397  1353.234486  2367.791394  1934.902312\n",
       "2      2375.726598  3017.861569  1496.913724  2620.756481  2357.003408\n",
       "3      1467.677248  2220.532612  1181.521401  1491.529684  1903.669717\n",
       "4      1949.033519  2400.175031  1204.608386  1713.527779  1824.986944\n",
       "...            ...          ...          ...          ...          ...\n",
       "29498  1289.230163  1991.285965  1178.917172  1283.131391  1222.833398\n",
       "29499  2007.638607  2876.992553  1325.959616  2008.751715  2183.280494\n",
       "29500  1364.185118  2148.467800  1147.881760  1383.008785  1147.514338\n",
       "29501  1713.124251  2284.655204  1263.797978  1751.759765  1155.093199\n",
       "29502  1720.344804  2382.447442  1417.939307  1830.297473  1845.863522\n",
       "\n",
       "[29503 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(xtrain_new)  # new features for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "894fb4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1469.153575</td>\n",
       "      <td>2237.965878</td>\n",
       "      <td>1147.596600</td>\n",
       "      <td>1437.517144</td>\n",
       "      <td>1330.530096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1916.271656</td>\n",
       "      <td>2444.779991</td>\n",
       "      <td>1363.144758</td>\n",
       "      <td>1749.671331</td>\n",
       "      <td>1623.095694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1883.679348</td>\n",
       "      <td>2485.462487</td>\n",
       "      <td>1275.299074</td>\n",
       "      <td>1769.756390</td>\n",
       "      <td>1459.980361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1261.308747</td>\n",
       "      <td>2287.177998</td>\n",
       "      <td>1318.664726</td>\n",
       "      <td>1104.563391</td>\n",
       "      <td>1564.743912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015.507177</td>\n",
       "      <td>2672.846791</td>\n",
       "      <td>1412.569964</td>\n",
       "      <td>2019.807894</td>\n",
       "      <td>1969.333572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7371</th>\n",
       "      <td>2344.282609</td>\n",
       "      <td>2959.448837</td>\n",
       "      <td>1221.421242</td>\n",
       "      <td>2341.591258</td>\n",
       "      <td>1885.883684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>2435.961849</td>\n",
       "      <td>3044.231779</td>\n",
       "      <td>1459.236498</td>\n",
       "      <td>2317.983593</td>\n",
       "      <td>2163.053391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373</th>\n",
       "      <td>1997.945586</td>\n",
       "      <td>2538.780874</td>\n",
       "      <td>1482.020072</td>\n",
       "      <td>2055.870060</td>\n",
       "      <td>2166.842416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>2840.548163</td>\n",
       "      <td>2998.807172</td>\n",
       "      <td>1399.889571</td>\n",
       "      <td>2639.089500</td>\n",
       "      <td>2470.309060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7375</th>\n",
       "      <td>1800.621407</td>\n",
       "      <td>2585.758701</td>\n",
       "      <td>1257.617914</td>\n",
       "      <td>1766.780924</td>\n",
       "      <td>1633.236228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7376 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4\n",
       "0     1469.153575  2237.965878  1147.596600  1437.517144  1330.530096\n",
       "1     1916.271656  2444.779991  1363.144758  1749.671331  1623.095694\n",
       "2     1883.679348  2485.462487  1275.299074  1769.756390  1459.980361\n",
       "3     1261.308747  2287.177998  1318.664726  1104.563391  1564.743912\n",
       "4     2015.507177  2672.846791  1412.569964  2019.807894  1969.333572\n",
       "...           ...          ...          ...          ...          ...\n",
       "7371  2344.282609  2959.448837  1221.421242  2341.591258  1885.883684\n",
       "7372  2435.961849  3044.231779  1459.236498  2317.983593  2163.053391\n",
       "7373  1997.945586  2538.780874  1482.020072  2055.870060  2166.842416\n",
       "7374  2840.548163  2998.807172  1399.889571  2639.089500  2470.309060\n",
       "7375  1800.621407  2585.758701  1257.617914  1766.780924  1633.236228\n",
       "\n",
       "[7376 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(xtest_new)  # new features for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ad35bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the root mean squared error with stacking is: 1477.241773650398\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression() # use a simply regressor for second layer\n",
    "reg=reg.fit(xtrain_new,y_train) # the predicted values as new feature in second layer\n",
    "y_pred = reg.predict(xtest_new) # the predicted values from test set are averaged and used as new X_test\n",
    "rmse = mean_squared_error(y_pred, y_test,squared=False)\n",
    "print( f\"the root mean squared error with stacking is: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e50e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
